{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Étape 1 : Traduction\n",
    "Happy Transformer : https://happytransformer.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/24/2025 16:33:05 - INFO - happytransformer.happy_transformer -   Using device: cpu\n",
      "03/24/2025 16:33:05 - INFO - happytransformer.happy_transformer -   Moving model to cpu\n",
      "03/24/2025 16:33:05 - INFO - happytransformer.happy_transformer -   Initializing a pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quel temps font-ils aujourd'hui et demain ?\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "from collections import defaultdict\n",
    "from curl_cffi import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import json\n",
    "\n",
    "def get_lang_tags(url):\n",
    "\n",
    "    responce = requests.get(url, impersonate=\"firefox133\")\n",
    "    page = soup(responce.text, 'html.parser')\n",
    "    table = page.find_all(\"td\")\n",
    "\n",
    "    dict_lang = defaultdict(str)\n",
    "    for r in range(0, len(table)-1, 2):\n",
    "        dict_lang[table[r].text] = table[r+1].text\n",
    "\n",
    "    return dict_lang\n",
    "\n",
    "url_lang = \"https://developers.google.com/admin-sdk/directory/v1/languages\"\n",
    "lang_tags = get_lang_tags(url_lang)\n",
    "\n",
    "# Sauvegarder le dictionnaire des langues en fichier json \n",
    "with open(\"lang_tags.json\", \"w\") as file:\n",
    "    json.dump(lang_tags, file, indent=4)\n",
    "\n",
    "source = \"en\"\n",
    "target = \"fr\"\n",
    "\n",
    "model_LANG = f\"Helsinki-NLP/opus-mt-{source}-{target}\"\n",
    "\n",
    "inputs = \"What's the weather like today and tomorrow?\"\n",
    "settings = TTSettings(do_sample=True, top_k=50, temperature=0.7)\n",
    "happy_tt = HappyTextToText(\"MARIAN\", model_LANG)\n",
    "\n",
    "outputs = happy_tt.generate_text(inputs, args=settings).text\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Étape 2 : Quantity Estimation\n",
    "Pour une évaluation au niveau de la phrase, il existe deux architectures différentes : Mono et Siamese.\n",
    "\n",
    "TransQuest : https://github.com/TharinduDR/TransQuest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Importer PyTorch\n",
    "from transquest.algo.sentence_level.siamesetransquest.run_model import SiameseTransQuestModel # Importer modèle Siamese\n",
    "from transquest.algo.sentence_level.monotransquest.run_model import MonoTransQuestModel # Importer modèle Mono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilhem/Documents/Master_TAL/Technique_Web/Venv_TransQuest/lib/python3.10/site-packages/transquest/algo/sentence_level/monotransquest/run_model.py:251: UserWarning: use_multiprocessing automatically disabled as xlmroberta fails when using multiprocessing for feature conversion.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00, 2125.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668252170085907 0.668252170085907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle pré-entraîné \"monotransquest-da-multilingual\".\n",
    "model = MonoTransQuestModel(\"xlmroberta\", \"TransQuest/monotransquest-da-multilingual\", num_labels=1, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "# Prédiction de la qualité de traduction pour une paire de phrases.\n",
    "pred, raw_output = model.predict([[inputs, outputs]])\n",
    "print(pred, raw_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle pré-entraîné \"siamesetransquest-da-multilingual\".\n",
    "model = SiameseTransQuestModel(\"TransQuest/siamesetransquest-da-multilingual\")\n",
    "\n",
    "# Prédiction de la qualité de traduction pour une paire de phrases.\n",
    "pred = model.predict([[inputs, outputs]])\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv_TransQuest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
